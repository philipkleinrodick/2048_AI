{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO SET DEPTH LIMIT ###\n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid = np.array([np.zeros(4) for i in range(4)])\n",
    "np.random.randint(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class board():\n",
    "    score =0\n",
    "    lose = 0\n",
    "    tile = 2\n",
    "    def __init__(self):\n",
    "        self.grid = np.array([np.zeros(4) for i in range(4)])\n",
    "        i = np.random.randint(4)\n",
    "        j = np.random.randint(4)\n",
    "        self.grid[i,j] = 2\n",
    "        k,l = i,j\n",
    "\n",
    "        while(i==k and l==j):\n",
    "            k = np.random.randint(4)\n",
    "            l = np.random.randint(4)\n",
    "        self.grid[k,l] = 2\n",
    "\n",
    "### Shift, merge, and move constitute one move ###        \n",
    "    def shift(self):\n",
    "        current = np.array([np.zeros(4) for i in range(4)])\n",
    "        for i in range(4):\n",
    "            position = 0\n",
    "            for j in range(4):\n",
    "                if self.grid[i][j] != 0:\n",
    "                    current[i][position] = self.grid[i][j]\n",
    "                    position+=1\n",
    "        self.grid = current\n",
    "    def merge(self):\n",
    "        #shift left, merge values, shift left\n",
    "        self.shift()\n",
    "        for i in range(4):\n",
    "            for j in range(3):\n",
    "                if self.grid[i][j] == self.grid[i][j+1] and self.grid[i][j] != 0:\n",
    "                    self.grid[i][j] *= 2\n",
    "                    self.score+= self.grid[i][j]\n",
    "                    if (self.grid[i][j]) > self.tile:\n",
    "                        self.tile = self.grid[i][j]\n",
    "                    self.grid[i][j+1] = 0\n",
    "        self.shift()\n",
    "        \n",
    "    def move(self, direction):\n",
    "        #Merge everything left.  Use flip and transpose for other orientations\n",
    "        self.temp = copy.deepcopy(self.grid)\n",
    "        if direction == 'u':\n",
    "            self.grid = np.transpose(self.grid)\n",
    "            self.merge()\n",
    "            self.grid = np.transpose(self.grid)\n",
    "        elif direction == 'd':\n",
    "            self.grid = np.flip(np.transpose(self.grid),1)\n",
    "            self.merge()\n",
    "            self.grid = np.transpose(np.flip(self.grid,1))\n",
    "        elif direction == 'r':\n",
    "            self.grid = np.flip(self.grid)\n",
    "            self.merge()\n",
    "            self.grid = np.flip(self.grid)\n",
    "        else:\n",
    "            self.merge()\n",
    "        \n",
    "### Check if the player has lost ###\n",
    "    def lost(self):\n",
    "        self.lose = 1\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                if self.grid[i][j] == 0:\n",
    "                    self.lose = 0 #Haven't lost yet\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                try:\n",
    "                    if (self.grid[i][j] == self.grid[i+1][j]):\n",
    "                        self.lose = 0\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    if (self.grid[i][j] == self.grid[i][j+1]):\n",
    "                        self.lose = 0\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "    def add_tile(self):\n",
    "        possibilities = []\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                if self.grid[i][j] == 0:\n",
    "                    possibilities.append((i,j))\n",
    "        value = np.random.choice([2,4], p=(.9,.1))\n",
    "        if possibilities:\n",
    "            a=possibilities[np.random.choice(len(possibilities))]\n",
    "            self.grid[a] = value\n",
    "    def legal_move(self):\n",
    "        score = self.score\n",
    "        legal_moves = []\n",
    "        temp_grid = self.grid\n",
    "        self.move('l')\n",
    "        if (not np.array_equal(self.grid,temp_grid)):\n",
    "            legal_moves.append('l')\n",
    "        self.grid = temp_grid\n",
    "        self.move('r')\n",
    "        if (not np.array_equal(self.grid, temp_grid)):\n",
    "            legal_moves.append('r')\n",
    "        self.grid = temp_grid\n",
    "        self.move('u')\n",
    "        if (not np.array_equal(self.grid, temp_grid)):\n",
    "            legal_moves.append('u')\n",
    "        self.grid = temp_grid\n",
    "        self.move('d')\n",
    "        if (not np.array_equal(self.grid, temp_grid)):\n",
    "            legal_moves.append('d')\n",
    "        self.grid = temp_grid\n",
    "        self.score = score\n",
    "        return legal_moves\n",
    "            \n",
    "    def random_game(self):\n",
    "        states = []\n",
    "        while (not self.lose):\n",
    "            move = np.random.choice(['l','r','u','d'])\n",
    "            states.append((self.grid, move))\n",
    "\n",
    "            self.move(move)\n",
    "            self.lost()\n",
    "            if (not np.array_equal(self.grid, self.temp)):\n",
    "                self.add_tile()\n",
    "#        print(self.grid)\n",
    "#        print(self.score)\n",
    "\n",
    "        return states\n",
    "    def random_game_initial_score(self, depth, initial_move =0):\n",
    "        #first iteration out of loop to get first move\n",
    "        counter = 0\n",
    "        if initial_move == 0:\n",
    "            move = np.random.choice(self.legal_move())\n",
    "            first_move = move\n",
    "        else:\n",
    "            move = initial_move\n",
    "            first_move = initial_move\n",
    "        self.move(move)\n",
    "        self.lost()\n",
    "        if (not np.array_equal(self.grid, self.temp)):\n",
    "            self.add_tile()\n",
    "        self.lost()\n",
    "        while (not self.lose and counter < depth):\n",
    "            counter += 1\n",
    "#             if (not self.legal_move()):\n",
    "#                 print(self.lose)\n",
    "#                 print(self.grid)\n",
    "#                 self.lost()\n",
    "#                 print(self.lose)\n",
    "            move = np.random.choice(self.legal_move())\n",
    "            self.move(move)\n",
    "            self.lost()\n",
    "            if (not np.array_equal(self.grid, self.temp)):\n",
    "                self.add_tile()\n",
    "            self.lost()\n",
    "        return first_move, self.score\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(game):\n",
    "    states = game.random_game()\n",
    "    score = game.score\n",
    "    initial_move = states[0][1]\n",
    "    return [initial_move, score]\n",
    "### Different game strategies here ###\n",
    "def monte_carlo(game):\n",
    "    def getmove(game):\n",
    "        grids = []\n",
    "        for i in range(100):\n",
    "            grids.append(copy.deepcopy(game))\n",
    "        move_scores = defaultdict(list)\n",
    "    \n",
    "\n",
    "#         p = Pool(5)\n",
    "\n",
    "#         move_and_score = p.map(test, grids)\n",
    "#         p.close()\n",
    "#         for i in move_and_score:\n",
    "#             move_scores[i[0]].append(i[1])\n",
    "\n",
    "        for game in grids:\n",
    "            state = game.random_game()\n",
    "            score = game.score\n",
    "            initial_move = state[0][1]\n",
    "            move_scores[initial_move].append( score)\n",
    "        score = 0\n",
    "        for key, value in move_scores.items():\n",
    "            if (sum(value)/len(value) >score ):\n",
    "                    move = key\n",
    "                    score = sum(value)/len(value)\n",
    "        return move\n",
    "            \n",
    "\n",
    "    states = []\n",
    "    while (not game.lose):\n",
    "        move = getmove(game)\n",
    "        states.append((game.grid, move))\n",
    "        game.move(move)\n",
    "        game.lost()\n",
    "        if (not np.array_equal(game.temp, game.grid)):\n",
    "            game.add_tile()\n",
    "#    print(game.grid)\n",
    "    print(game.score)\n",
    "    print(game.tile)\n",
    "    return states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_new_random(game, depth):\n",
    "    def getmove(game):\n",
    "        grids = []\n",
    "        for i in range(10):\n",
    "            grids.append(copy.deepcopy(game))\n",
    "        move_scores = defaultdict(list)\n",
    "        for games in grids:\n",
    "            initial_move, score = games.random_game_initial_score(depth)\n",
    "            move_scores[initial_move].append( score)\n",
    "        score = 0\n",
    "        for key, value in move_scores.items():\n",
    "            print(key,sum(value)/len(value))\n",
    "            if (sum(value)/len(value) >score ):\n",
    "                    move = key\n",
    "                    score = sum(value)/len(value)\n",
    "        print(move, score)\n",
    "        print(game.grid)\n",
    "        print()\n",
    "        return move\n",
    "            \n",
    "\n",
    "    states = []\n",
    "    while (not game.lose):\n",
    "        move = getmove(game)\n",
    "        #states.append((game.grid, move))\n",
    "        game.move(move)\n",
    "        game.lost()\n",
    "        if (not np.array_equal(game.temp, game.grid)):\n",
    "            game.add_tile()\n",
    "        game.lost()\n",
    "#    print(game.grid)\n",
    "    print(game.score)\n",
    "    print(game.tile)\n",
    "    #return states\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_monte_carlo_new_random(game, depth):\n",
    "    def getmove(game):\n",
    "        grids = []\n",
    "        possible_moves = game.legal_move()\n",
    "#        print(possible_moves)\n",
    "        for i in range(100):\n",
    "            grids.append(copy.deepcopy(game))\n",
    "        move_scores = defaultdict(list)\n",
    "        i=0\n",
    "        for games in grids:\n",
    "            initial_move, score = games.random_game_initial_score(depth, possible_moves[i])\n",
    "            move_scores[initial_move].append( score)\n",
    "            i+=1\n",
    "            i=i%(len(possible_moves))\n",
    "        score = 0\n",
    "        for key, value in move_scores.items():\n",
    "            print(key,sum(value)/len(value))\n",
    "            if (sum(value)/len(value) >score ):\n",
    "                    move = key\n",
    "                    score = sum(value)/len(value)\n",
    "        print(move, score)\n",
    "        return move\n",
    "            \n",
    "\n",
    "    states = []\n",
    "    while (not game.lose):\n",
    "        move = getmove(game)\n",
    "        print(game.grid)\n",
    "        #states.append((game.grid, move))\n",
    "        game.move(move)\n",
    "        game.lost()\n",
    "        if (not np.array_equal(game.temp, game.grid)):\n",
    "            game.add_tile()\n",
    "        game.lost()\n",
    "#    print(game.grid)\n",
    "    print(game.score)\n",
    "    print(game.tile)\n",
    "    #return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Board' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7754017ec40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbetter_monte_carlo_new_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Board' is not defined"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "np.random.seed(1)\n",
    "for i in range(1):\n",
    "    board = board()\n",
    "    better_monte_carlo_new_random(board, 10)\n",
    "print(time.time()-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "board = Board()\n",
    "board.grid\n",
    "better_monte_carlo_new_random(board, 100000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dqn():\n",
    "    def __init__(self, game):\n",
    "        self.gamma = 0.5\n",
    "        self.short_memory = np.array([])\n",
    "        self.learning_rate = 0.001\n",
    "        self.game = game\n",
    "        self.epsilon = 0\n",
    "        self.memory = []\n",
    "        self.model = self.buildmodel()\n",
    "    def buildmodel(self, weights=None):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(16, activation='relu', input_dim = 16))\n",
    "#        model.add(Dropout(0.15))\n",
    "#        model.add(Dense(output_dim=120, activation='relu'))\n",
    "#         model.add(Dropout(0.15))\n",
    "#         model.add(Dense(output_dim=120, activation='relu'))\n",
    "#        model.add(Dropout(0.15))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "#        model.add(Dropout(0.15))\n",
    "        model.add(Dense(4, activation='linear'))\n",
    "        opt = Adam(lr=self.learning_rate)\n",
    "        model.compile(loss='log', optimizer=opt)\n",
    "        \n",
    "\n",
    "        print(\"Successfully built model\")\n",
    "        return model\n",
    "\n",
    "        if weights:\n",
    "            model.load_weights(weights)\n",
    "        return model\n",
    "    def get_state(self):\n",
    "        return self.game.grid.reshape(1,16)\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def replay_new(self, memory):\n",
    "        if len(memory) > 1000:\n",
    "            minibatch = random.sample(memory, 1000)\n",
    "        else:\n",
    "            minibatch = memory\n",
    "        for state, action, reward, next_state, lost in minibatch:\n",
    "            pred_move = self.model.predict(state)\n",
    "            pred_next_move = self.model.predict(next_state)\n",
    "            target = reward\n",
    "\n",
    "            if not lost:\n",
    "                target = reward + self.gamma * np.max(pred_next_move[0])\n",
    "            pred_move[0][action] = target\n",
    "            \n",
    "            self.model.fit(state, pred_move, epochs=10, verbose=0)\n",
    "    def train_short_memory(self, state, action, reward, next_state, lost, games_counter):\n",
    "        pred_move = self.model.predict(state)\n",
    "        pred_next_move = self.model.predict(next_state)\n",
    "        target = reward\n",
    "\n",
    "        if not lost:\n",
    "            target = reward + self.gamma * np.max(pred_next_move[0])\n",
    "        pred_move[0][action] = target\n",
    "            \n",
    "        self.model.fit(state, pred_move, epochs=10, verbose=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.losses' has no attribute 'huber_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3a38d78d2427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-208b5b1d49d8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, game)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuildmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-208b5b1d49d8>\u001b[0m in \u001b[0;36mbuildmodel\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhuber_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.losses' has no attribute 'huber_loss'"
     ]
    }
   ],
   "source": [
    "game = board()\n",
    "dqn = dqn(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_move(i):\n",
    "    if i == 0:\n",
    "        return 'l'\n",
    "    if i ==1:\n",
    "        return 'r'\n",
    "    if i == 2:\n",
    "        return 'u'\n",
    "    if i == 3:\n",
    "        return 'd'\n",
    "def move_to_int(i):\n",
    "    if i=='l':\n",
    "        return 0\n",
    "    if i == 'r':\n",
    "        return 1\n",
    "    if i == 'u':\n",
    "        return 2\n",
    "    if i == 'd':\n",
    "        return 3\n",
    "def run():\n",
    "    games_counter = 0\n",
    "    score_plot = []\n",
    "    counter_plot = []\n",
    "    record = 0\n",
    "    print(dqn.game.grid)\n",
    "    while games_counter < 300:\n",
    "        dqn.game = board()\n",
    "        while not dqn.game.lose:\n",
    "            dqn.epsilon = 80*(.97**games_counter)\n",
    "            \n",
    "            state_old = dqn.get_state()\n",
    "            prev_score = dqn.game.score\n",
    "            if np.random.randint(0,200)< dqn.epsilon:\n",
    "                legal_moves = dqn.game.legal_move()\n",
    "                final_move = np.random.choice(legal_moves)\n",
    "            else:\n",
    "                prediction = dqn.model.predict(state_old.reshape(1,16))\n",
    "                final_move = np.argmax(prediction[0])\n",
    "            final_move = int_to_move(final_move)\n",
    "            temp = copy.deepcopy(dqn.game.grid)\n",
    "\n",
    "#            print(\"+++++++++++++++++++++++++++++++\")\n",
    "#            print(dqn.game.grid, final_move)\n",
    "            dqn.game.move(final_move)\n",
    "            if (not np.array_equal(temp, dqn.game.grid)):\n",
    "                game.add_tile()\n",
    "            dqn.game.add_tile()\n",
    "            final_move = move_to_int(final_move)\n",
    "            state_new = dqn.get_state()\n",
    "            if dqn.game.score == prev_score:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = np.log2(dqn.game.score - prev_score)\n",
    "            done = dqn.game.lost()\n",
    "            \n",
    "            if done:\n",
    "                reward -= 1\n",
    "            dqn.train_short_memory(state_old, final_move, reward, state_new, done, games_counter)\n",
    "            \n",
    "            dqn.remember(state_old, final_move, reward, state_new, done)\n",
    "            \n",
    "        dqn.replay_new(dqn.memory)\n",
    "        games_counter +=1\n",
    "        print(\"game\", games_counter, \"score\", dqn.game.score)\n",
    "    dqn.model.save_weights('weights.hdf5')\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'dqn' has no attribute 'game'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b7204ae7f4f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-0d7e0e52fc11>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcounter_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mgames_counter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'dqn' has no attribute 'game'"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
